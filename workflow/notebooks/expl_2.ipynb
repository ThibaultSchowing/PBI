{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450ff611",
   "metadata": {},
   "source": [
    "# PhageScope Pipeline\n",
    "\n",
    "Basic packages \n",
    "\n",
    "The PhageScope data are downloaded via snakemake and reports generated on up to 50k randomly selected datapoint. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f269099",
   "metadata": {},
   "source": [
    "## File list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a418ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "data_dir = \"../data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cacdf4f",
   "metadata": {},
   "source": [
    "### Protein Metadata\n",
    "\n",
    "Temporary creation of big lists for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38561323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulators\n",
    "chunk_num = 0\n",
    "total_rows = 0\n",
    "phage_ids = []\n",
    "protein_ids = []\n",
    "source = [] # Source of the protein, e.g. DDBJ, CHVD, etc. match the directory names for the fasta files\n",
    "\n",
    "\n",
    "for chunk in pd.read_csv(os.path.join(data_dir, \"merged/merged_annotated_proteins_metadata.csv\"), chunksize=10000):\n",
    "    total_rows += len(chunk)\n",
    "    phage_ids.extend(chunk['Phage_ID'].tolist())\n",
    "    protein_ids.extend(chunk['Protein_ID'].tolist())\n",
    "    source.extend(chunk['Phage_source'].tolist())\n",
    "\n",
    "\n",
    "    # ------------------------------\n",
    "    chunk_num += 1\n",
    "    if chunk_num >= 55:  # Limit to 5 chunks for demonstration\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de216c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(source).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#transcription_terminator_metadata = pd.read_csv(os.path.join(data_dir, \"merged/merged_transcription_terminator_metadata.csv\"))\n",
    "#phage_metadata = pd.read_csv(os.path.join(data_dir, \"merged/merged_phage_metadata.csv\"))\n",
    "#phage_protein_metadata = pd.read_csv(os.path.join(data_dir, \"merged/merged_phage_protein_metadata.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2bd443",
   "metadata": {},
   "source": [
    "## Merging protein and phage Fasta\n",
    "\n",
    "Some sources have one fasta file per protein, other have one fasta file containing all proteins. \n",
    "\n",
    "In total, there are more than 23 milion fasta files (just protein !) Some sources have one file containing multiple sequences, while other sources have one fasta file per sequence. \n",
    "\n",
    "```\n",
    "Unique sources: 13\n",
    "RefSeq: 480642 FASTA files\n",
    "IGVD: 1 FASTA files\n",
    "PhagesDB: 351898 FASTA files\n",
    "GPD: 7616044 FASTA files\n",
    "GOV2: 1 FASTA files\n",
    "CHVD: 1 FASTA files\n",
    "MGV: 10517011 FASTA files\n",
    "DDBJ: 17391 FASTA files\n",
    "STV: 1 FASTA files\n",
    "EMBL: 11095 FASTA files\n",
    "TemPhD: 3465586 FASTA files\n",
    "GVD: 746146 FASTA files\n",
    "Genbank: 217128 FASTA files\n",
    "Total fasta files found: 23422945\n",
    "```\n",
    "\n",
    "To obtain the sequence from the protein ID, we should be able to query the sequences at will and for this, having a coeherent database is vital. We will then merge the sequences in one file per source which should allow later to create a performant database, which is not possible with 23 million files. \n",
    "\n",
    "The structure is like this: \n",
    "\n",
    "```\n",
    "protein_fasta/\n",
    "  └── source1/\n",
    "        ├── source1/\n",
    "        │     ├── phageA/\n",
    "        │     │     ├── file1.fasta\n",
    "        │     │     └── file2.fasta\n",
    "        │     └── phageB/\n",
    "        │           └── file3.fasta\n",
    "  └── source2/\n",
    "        └── single.fasta\n",
    "\n",
    "```\n",
    "\n",
    "### Merging Fasta files per source\n",
    "\n",
    "Using the script `merge_protein_fasta.py` with the snakemake rules `snakemake --cores 2 data/protein_fasta_merged/DDBJ.fasta` for each file, it will merge the files if necessary into data/protein_fasta_merged. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0af2e6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Visualize with `snakemake --cores 4 --dag | dot -Tsvg > dag_all.svg`\n",
    "\n",
    "More complete command with cache and logging: `snakemake --cache --printshellcmds --reason --timestamp --cores 8 `\n",
    "\n",
    "## Activation du cache pour les règles lourdes\n",
    "\n",
    "Créer les répertoires nécessaires: \n",
    "\n",
    "```\n",
    "sudo mkdir -p /mnt/snakemake-cache\n",
    "sudo chown $(whoami) /mnt/snakemake-cache\n",
    "\n",
    "```\n",
    "\n",
    "`export SNAKEMAKE_OUTPUT_CACHE=/mnt/snakemake-cache/`\n",
    "\n",
    "Le caching est activé pour les règles de téléchargement. \n",
    "\n",
    "Afin d'exécuter les scripts dans le bon environnement, on export l'environement pixi avec `pixi workspace export conda-environment -e base envs/pixi_base_enf.yaml`\n",
    "\n",
    "On exécute snakemake depuis pixi (afin d'être sûr que ça soit le bon snakemake) et on donne les arguments conda nécessaires (exemple avec merge_annotated_proteins_metadata_tsvs): \n",
    "\n",
    "`pixi run snakemake all --cache --use-conda --conda-frontend mamba --printshellcmds --cores 2`\n",
    "\n",
    "Attention: certain crashes peuvent être dûs à une surcharge I/O en cas de multithreading trop important. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb17a5",
   "metadata": {},
   "source": [
    "# Phage Metadata Exploration\n",
    "\n",
    "Explore the data for further pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c86da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78146fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24913/856263692.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_phages = phage_metadata.groupby('Phage_source').apply(lambda x: x.sample(n=10, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Read data/merged/merged_phage_metadata.csv\n",
    "phage_metadata = pd.read_csv(os.path.join(data_dir, \"merged/merged_phage_metadata.csv\"))\n",
    "\n",
    "\n",
    "# For each Phage_source, get a sample of 10 phages in a new dataframe\n",
    "\n",
    "sampled_phages = phage_metadata.groupby('Phage_source').apply(lambda x: x.sample(n=10, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "514234e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phage_ID</th>\n",
       "      <th>Phage_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Actinoplanes_phage_phiAsp2</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Arthrobacter_phage_Shoya</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Microbacterium_phage_LeeroyJenkins</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Mycobacterium_phage_Kboogie</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Microbacterium_phage_Haunter</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Mycobacterium_phage_JC27</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Mycobacterium_phage_Funston</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Arthrobacter_phage_King2</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Mycobacterium_phage_Pharsalus</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Mycobacterium_phage_Jobu08</td>\n",
       "      <td>PhagesDB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Phage_ID Phage_source\n",
       "100          Actinoplanes_phage_phiAsp2     PhagesDB\n",
       "101            Arthrobacter_phage_Shoya     PhagesDB\n",
       "102  Microbacterium_phage_LeeroyJenkins     PhagesDB\n",
       "103         Mycobacterium_phage_Kboogie     PhagesDB\n",
       "104        Microbacterium_phage_Haunter     PhagesDB\n",
       "105            Mycobacterium_phage_JC27     PhagesDB\n",
       "106         Mycobacterium_phage_Funston     PhagesDB\n",
       "107            Arthrobacter_phage_King2     PhagesDB\n",
       "108       Mycobacterium_phage_Pharsalus     PhagesDB\n",
       "109          Mycobacterium_phage_Jobu08     PhagesDB"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to keep only phage id and phage source\n",
    "tmp = sampled_phages[['Phage_ID', 'Phage_source']]\n",
    "\n",
    "# Get only rows with source PhagesDB\n",
    "tmp[tmp['Phage_source'] == 'PhagesDB']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
